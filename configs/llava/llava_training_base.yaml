defaults:
  - checkpoints: default
  - image_checkpoints: clip-336
  - _self_

model:
  version: v1
  tune_mm_mlp_adapter: True
  mm_vision_select_layer: -2
  mm_use_im_start_end: False
  mm_use_im_patch_token: False
  mm_projector_type: "mlp2x_gelu"
  max_sequence_length: 2048

data:
  data_path: ./dataset/sft_data_llava7B
  lazy_preprocess: True
  image_folder: null

training:
  model_max_length: 2048
  seed: 42
  # These are some args from the huggingface trainer (from which the llava trainer arguments derive), and are not exhaustive
  bf16: True  # can be set to True on A6000s or A100s
  tf32: False
  fp16: True
  output_dir: ./output
  num_train_epochs: null
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  gradient_accumulation_steps: 1
  evaluation_strategy: "steps"
  eval_steps: 100
  save_strategy: "steps"
  save_steps: 100
  save_total_limit: 10
  learning_rate: 2e-5
  weight_decay: 0.
  warmup_ratio: 0.03
  lr_scheduler_type: "cosine"
  logging_steps: 1
  gradient_checkpointing: True
  report_to: ["wandb"]
  deepspeed: opadpo/deepspeed_state_1_config.json
  use_flash_attention: True
  dataloader_num_workers: 8
  use_all_available_cores: True
  # The update frequency for TQDM progress bars of the Huggingface trainer
  logging_interval_seconds: 60
  increased_reproducibility: True
  lora_enable: False

inference:
  batch_size: 1
  dataloader_drop_last: False
  num_workers: 1
  pin_memory: False
  dataloader_num_workers: 8
  use_all_available_cores: False
  dataloader_pin_memory: False
  max_new_tokens: 200
  temperature: 0.0
  do_sample: False
  increased_reproducibility: True
  seed: 42

wandb_project: ""
